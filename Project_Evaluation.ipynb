{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selected Model Hyper-Paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'hidden_dim': 128, 'batch_size': 128, 'n1_gat_layers': 1, 'n2_gru_layers': 1, 'num_heads': 4, 'dropout': 0.04033931265087129, 'learning_rate': 0.00015574186652855083, 'pos_lambda': 0.5756532880616873, 'bios_hidden_dim': 32, 'pres_hidden_dim': 64, 'k': 5, 'num_clusters': 240}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run preprocess pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import preprocess\n",
    "import imp\n",
    "imp.reload(preprocess)\n",
    "\n",
    "data = preprocess.preprocess_pipeline(num_clusters=hyperparameters['num_clusters'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Dataset\n",
    "import imp\n",
    "imp.reload(Dataset)\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "k = hyperparameters['k']\n",
    "\n",
    "train_labels = torch.tensor(data[\"y_train\"][['mort_30day', 'prolonged_stay', 'readmission_30day']].values, dtype=torch.float32).to(DEVICE)\n",
    "val_labels = torch.tensor(data[\"y_val\"][['mort_30day', 'prolonged_stay', 'readmission_30day']].values, dtype=torch.float32).to(DEVICE)\n",
    "test_labels = torch.tensor(data[\"y_test\"][['mort_30day', 'prolonged_stay', 'readmission_30day']].values, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "\n",
    "batch_size = hyperparameters['batch_size']\n",
    "datasets = {x: Dataset.PatientDataset(d, y, core=data[\"padded_tensor_core\"], padding_mask=m, padding_mask_core=data[\"padding_mask_core\"], k=k ,notes=n, bios=b, prescriptions=p) for x, d, y, m, n, b, p in\n",
    "        zip(['train', 'val', 'test'], [data[\"padded_tensor_train\"], data[\"padded_tensor_val\"], data[\"padded_tensor_test\"]],\n",
    "            [train_labels, val_labels, test_labels],\n",
    "            [data[\"padding_mask_train\"], data[\"padding_mask_val\"], data[\"padding_mask_test\"]],\n",
    "            [data[\"notes_df_train\"].embeddings.values.tolist(),\n",
    "             data[\"notes_df_val\"].embeddings.values.tolist(),\n",
    "             data[\"notes_df_test\"].embeddings.values.tolist()],\n",
    "             [torch.tensor(data[\"bio_train\"].values >= 1, dtype=torch.float32).to(DEVICE),\n",
    "              torch.tensor(data[\"bio_val\"].values >= 1, dtype=torch.float32).to(DEVICE),\n",
    "              torch.tensor(data[\"bio_test\"].values >= 1, dtype=torch.float32).to(DEVICE)],\n",
    "              [torch.tensor(data[\"prescriptions_train\"].values, dtype=torch.float32).to(DEVICE), \n",
    "              torch.tensor(data[\"prescriptions_val\"].values, dtype=torch.float32).to(DEVICE), \n",
    "              torch.tensor(data[\"prescriptions_test\"].values, dtype=torch.float32).to(DEVICE)])}\n",
    "dataloaders = {x: DataLoader(datasets[x], batch_size=batch_size, shuffle=True) for x in ['train', 'val', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model \n",
    "import imp\n",
    "imp.reload(Model)\n",
    "model = Model.GraphGRUMortalityModel(input_dim=data[\"padded_tensor_train\"].shape[2], hidden_dim=hyperparameters['hidden_dim'], \n",
    "                                     n1_gat_layers=1, n2_gru_layers=1, \n",
    "                                     X_core=data[\"padded_tensor_core\"], num_of_bios=data[\"bio_train\"].shape[1],\n",
    "                                     num_prescriptions=data[\"prescriptions_train\"].shape[-1], \n",
    "                                     bios_hidden_dim=hyperparameters['bios_hidden_dim'], pres_hidden_dim=hyperparameters['pres_hidden_dim'], \n",
    "                                     core_padding_mask=data[\"padding_mask_core\"], num_heads=hyperparameters['num_heads'], \n",
    "                                     dropout=hyperparameters['dropout'], seq_len=data[\"padded_tensor_train\"].shape[1], k=k, gnn_flag=True).to(DEVICE)\n",
    "torch.manual_seed(1234)\n",
    "model.train_all(dataloaders, datasets, epochs=10, learning_rate=hyperparameters['learning_rate'], pos_lambda=hyperparameters['pos_lambda'])\n",
    "print(\"Training completed. Validating on test set...\")\n",
    "\n",
    "model.validate(dataloaders['test'], datasets['test'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model and related objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model.save_model(r\"./data/grapth-gru-model.pt\")\n",
    "\n",
    "data_for_inference = {\n",
    "    \"X_core\": data[\"X_core\"],\n",
    "    \"padding_mask_core\": data[\"padding_mask_core\"],\n",
    "    \"scaler\": data[\"scaler\"],\n",
    "    \"baseline_df\": data[\"baseline_df\"],\n",
    "    \"orgs\": data[\"orgs\"],\n",
    "    \"drugs\": data[\"drugs\"]\n",
    "}\n",
    "\n",
    "with open(r\"./data/data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "test_subjects = data[\"X_test\"][\"subject_id\"].drop_duplicates()\n",
    "y_test = data[\"y_test\"]\n",
    "\n",
    "test_subjects.to_csv(r\"./data/test_subjects.csv\")\n",
    "y_test.to_csv(r\"./data/y_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Line Model Traning - Same split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model \n",
    "import imp\n",
    "imp.reload(Model)\n",
    "base_model = Model.GraphGRUMortalityModel(input_dim=data[\"padded_tensor_train\"].shape[2], hidden_dim=hyperparameters['hidden_dim'], \n",
    "                                     n1_gat_layers=1, n2_gru_layers=1, \n",
    "                                     X_core=data[\"padded_tensor_core\"], num_of_bios=data[\"bio_train\"].shape[1],\n",
    "                                     num_prescriptions=data[\"prescriptions_train\"].shape[-1], \n",
    "                                     bios_hidden_dim=hyperparameters['bios_hidden_dim'], pres_hidden_dim=hyperparameters['pres_hidden_dim'], \n",
    "                                     core_padding_mask=data[\"padding_mask_core\"], num_heads=hyperparameters['num_heads'], \n",
    "                                     dropout=hyperparameters['dropout'], seq_len=data[\"padded_tensor_train\"].shape[1], k=k, gnn_flag=False).to(DEVICE)\n",
    "torch.manual_seed(1234)\n",
    "base_model.train_all(dataloaders, datasets, epochs=10, learning_rate=0.001)\n",
    "print(\"Training completed. Validating on test set...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUPR & AUROC Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
    "\n",
    "# Additional Analysis: Individual ROC and PR curves for each task\n",
    "print(\"Generating predictions on test set...\")\n",
    "y_trues, y_preds = model.validate(dataloaders['test'], datasets['test'], return_predictions=True)\n",
    "\n",
    "# Define task names for better visualization\n",
    "task_names = ['Mortality (30-day)', 'Prolonged Stay', 'Readmission (30-day)']\n",
    "\n",
    "# Convert to numpy arrays for easier handling\n",
    "for i in range(3):\n",
    "    y_trues[i] = np.array(y_trues[i])\n",
    "    y_preds[i] = np.array(y_preds[i])\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Individual ROC and PR Curves for Each Task', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Colors: model in blue/green/red, baseline in orange\n",
    "model_colors = 'blue'\n",
    "baseline_color = 'orange'\n",
    "\n",
    "# Load baseline model predictions\n",
    "# Assumes baseline_model is loaded and has a .validate method like the main model\n",
    "y_trues_baseline, y_preds_baseline = base_model.validate(dataloaders['test'], datasets['test'], return_predictions=True)\n",
    "for i in range(3):\n",
    "    y_trues_baseline[i] = np.array(y_trues_baseline[i])\n",
    "    y_preds_baseline[i] = np.array(y_preds_baseline[i])\n",
    "\n",
    "for i, task_name in enumerate(task_names):\n",
    "    # Model\n",
    "    y_true = y_trues[i]\n",
    "    y_pred = y_preds[i]\n",
    "    # Baseline\n",
    "    y_true_base = y_trues_baseline[i]\n",
    "    y_pred_base = y_preds_baseline[i]\n",
    "    \n",
    "    # ROC Curve\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fpr_base, tpr_base, _ = roc_curve(y_true_base, y_pred_base)\n",
    "    roc_auc_base = auc(fpr_base, tpr_base)\n",
    "    \n",
    "    axes[0, i].plot(fpr, tpr, color=model_colors, lw=2, \n",
    "                   label=f'Model AUC = {roc_auc:.3f}')\n",
    "    axes[0, i].plot(fpr_base, tpr_base, color=baseline_color, lw=2, linestyle='--', \n",
    "                   label=f'Baseline AUC = {roc_auc_base:.3f}')\n",
    "    axes[0, i].plot([0, 1], [0, 1], color='gray', lw=1, linestyle=':', alpha=0.8)\n",
    "    axes[0, i].set_xlim([0.0, 1.0])\n",
    "    axes[0, i].set_ylim([0.0, 1.05])\n",
    "    axes[0, i].set_xlabel('False Positive Rate')\n",
    "    axes[0, i].set_ylabel('True Positive Rate')\n",
    "    axes[0, i].set_title(f'ROC Curve - {task_name}')\n",
    "    axes[0, i].legend(loc=\"lower right\")\n",
    "    axes[0, i].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Precision-Recall Curve\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_pred)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    precision_base, recall_base, _ = precision_recall_curve(y_true_base, y_pred_base)\n",
    "    pr_auc_base = auc(recall_base, precision_base)\n",
    "    \n",
    "    axes[1, i].plot(recall, precision, color=model_colors, lw=2, \n",
    "                   label=f'Model AP = {pr_auc:.3f}')\n",
    "    axes[1, i].plot(recall_base, precision_base, color=baseline_color, lw=2, linestyle='--', \n",
    "                   label=f'Baseline AP = {pr_auc_base:.3f}')\n",
    "    axes[1, i].set_xlim([0.0, 1.0])\n",
    "    axes[1, i].set_ylim([0.0, 1.05])\n",
    "    axes[1, i].set_xlabel('Recall')\n",
    "    axes[1, i].set_ylabel('Precision')\n",
    "    axes[1, i].set_title(f'Precision-Recall Curve - {task_name}')\n",
    "    axes[1, i].legend(loc=\"lower left\")\n",
    "    axes[1, i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Task':<20} {'Model AUC':<12} {'Baseline AUC':<15} {'Model AP':<12} {'Baseline AP':<15}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "for i, task_name in enumerate(task_names):\n",
    "    # Calculate metrics for model\n",
    "    fpr, tpr, _ = roc_curve(y_trues[i], y_preds[i])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    precision, recall, _ = precision_recall_curve(y_trues[i], y_preds[i])\n",
    "    pr_auc = auc(recall, precision)\n",
    "    \n",
    "    # Calculate metrics for baseline\n",
    "    fpr_base, tpr_base, _ = roc_curve(y_trues_baseline[i], y_preds_baseline[i])\n",
    "    roc_auc_base = auc(fpr_base, tpr_base)\n",
    "    precision_base, recall_base, _ = precision_recall_curve(y_trues_baseline[i], y_preds_baseline[i])\n",
    "    pr_auc_base = auc(recall_base, precision_base)\n",
    "    \n",
    "    print(f\"{task_name:<20} {roc_auc:<12.3f} {roc_auc_base:<15.3f} {pr_auc:<12.3f} {pr_auc_base:<15.3f}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calibration Anaylsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.metrics import brier_score_loss\n",
    "import seaborn as sns\n",
    "\n",
    "def calculate_ece(y_true, y_prob, n_bins=10):\n",
    "    \"\"\"\n",
    "    Calculate Expected Calibration Error (ECE)\n",
    "    \"\"\"\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    \n",
    "    ece = 0\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = (y_prob > bin_lower) & (y_prob <= bin_upper)\n",
    "        prop_in_bin = in_bin.mean()\n",
    "        \n",
    "        if prop_in_bin > 0:\n",
    "            accuracy_in_bin = y_true[in_bin].mean()\n",
    "            avg_confidence_in_bin = y_prob[in_bin].mean()\n",
    "            ece += np.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "    \n",
    "    return ece\n",
    "\n",
    "def calculate_mce(y_true, y_prob, n_bins=10):\n",
    "    \"\"\"\n",
    "    Calculate Maximum Calibration Error (MCE)\n",
    "    \"\"\"\n",
    "    bin_boundaries = np.linspace(0, 1, n_bins + 1)\n",
    "    bin_lowers = bin_boundaries[:-1]\n",
    "    bin_uppers = bin_boundaries[1:]\n",
    "    \n",
    "    mce = 0\n",
    "    for bin_lower, bin_upper in zip(bin_lowers, bin_uppers):\n",
    "        in_bin = (y_prob > bin_lower) & (y_prob <= bin_upper)\n",
    "        prop_in_bin = in_bin.mean()\n",
    "        \n",
    "        if prop_in_bin > 0:\n",
    "            accuracy_in_bin = y_true[in_bin].mean()\n",
    "            avg_confidence_in_bin = y_prob[in_bin].mean()\n",
    "            mce = max(mce, np.abs(avg_confidence_in_bin - accuracy_in_bin))\n",
    "    \n",
    "    return mce\n",
    "\n",
    "def plot_calibration_curve(y_true, y_prob, task_name, n_bins=10, ax=None):\n",
    "    \"\"\"\n",
    "    Plot calibration curve with reliability diagram\n",
    "    \"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "    \n",
    "    # Calculate calibration curve\n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "        y_true, y_prob, n_bins=n_bins, strategy='uniform'\n",
    "    )\n",
    "    \n",
    "    # Plot reliability diagram\n",
    "    ax.plot(mean_predicted_value, fraction_of_positives, \"s-\", \n",
    "            label=f'{task_name} (ECE: {calculate_ece(y_true, y_prob, n_bins):.3f})',\n",
    "            linewidth=2, markersize=8)\n",
    "    \n",
    "    # Plot perfect calibration line\n",
    "    ax.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\", linewidth=2)\n",
    "    \n",
    "    # Calculate and display metrics\n",
    "    ece = calculate_ece(y_true, y_prob, n_bins)\n",
    "    mce = calculate_mce(y_true, y_prob, n_bins)\n",
    "    brier = brier_score_loss(y_true, y_prob)\n",
    "    \n",
    "    ax.set_xlabel('Mean Predicted Probability', fontsize=12)\n",
    "    ax.set_ylabel('Fraction of Positives', fontsize=12)\n",
    "    ax.set_title(f'Calibration Curve - {task_name}', fontsize=14, fontweight='bold')\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add metrics as text\n",
    "    metrics_text = f'ECE: {ece:.3f}\\nMCE: {mce:.3f}\\nBrier Score: {brier:.3f}'\n",
    "    ax.text(0.05, 0.95, metrics_text, transform=ax.transAxes, \n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "            fontsize=10)\n",
    "    \n",
    "    return ax, ece, mce, brier\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_calibration_curve(y_true, y_prob, n_bins=5, ax=None, hist=True, normalize=False):\n",
    "    prob_true, prob_pred = calibration_curve(y_true, y_prob, n_bins=n_bins, strategy='quantile')\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    if hist:\n",
    "        ax.hist(y_prob, weights=np.ones_like(y_prob) / len(y_prob), alpha=.4,\n",
    "               bins=np.maximum(10, n_bins))\n",
    "    ax.plot([0, 1], [0, 1], ':', c='k')\n",
    "    curve = ax.plot(prob_pred, prob_true, marker=\"o\")\n",
    "\n",
    "    ax.set_xlabel(\"predicted probability\")\n",
    "    ax.set_ylabel(\"fraction of positive samples\")\n",
    "\n",
    "    ax.set(aspect='equal')\n",
    "    return curve\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for calibration analysis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "print(\"Generating predictions for calibration analysis...\")\n",
    "\n",
    "# Get predictions from both models\n",
    "y_trues_model, y_preds_model = model.validate(dataloaders['test'], datasets['test'], return_predictions=True, calibrate=True)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "task_names = ['Mortality (30-day)', 'Prolonged Stay', 'Readmission (30-day)']\n",
    "model_predictions = {}\n",
    "true_labels = {}\n",
    "\n",
    "for i, task_name in enumerate(task_names):\n",
    "    model_predictions[task_name] = np.array(y_preds_model[i])\n",
    "    true_labels[task_name] = np.array(y_trues_model[i])\n",
    "\n",
    "# Create comprehensive calibration plots\n",
    "print(\"Creating calibration plots...\")\n",
    "\n",
    "# Set up the plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "fig.suptitle('Model Calibration Analysis: Graph-GRU vs Baseline', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, task_name in enumerate(task_names):\n",
    "    ax_model = axes[i]\n",
    "    plot_calibration_curve(true_labels[task_name], model_predictions[task_name], \n",
    "                          ax=ax_model, n_bins=10)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Calibration plots created successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- 100%|██████████| 10/10 [00:07<00:00,  1.38it/s]\n",
    "Test Mortality: AUC-ROC: 0.85  AP: 0.52\n",
    "Test Prolonged Stay: AUC-ROC: 0.82  AP: 0.80\n",
    "Test Readmission: AUC-ROC: 0.62  AP: 0.08 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Test Mortality: AUC-ROC: 0.87  AP: 0.52\n",
    "Test Prolonged Stay: AUC-ROC: 0.83  AP: 0.81\n",
    "Test Readmission: AUC-ROC: 0.62  AP: 0.08 -->"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "1ddf7f8e5bd9405fb67d08725d4983e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "black",
      "description_width": ""
     }
    },
    "56463d5b8bee4a088d7c9d7613fd6e20": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "auto"
     }
    },
    "78c007406aa24a9f80d79038bb6e14a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb91ad428b04480f995aced9d968ba18",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1ddf7f8e5bd9405fb67d08725d4983e5",
      "value": 84
     }
    },
    "befffb4f7372406291ce48f9bfcdb07b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56463d5b8bee4a088d7c9d7613fd6e20",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_da6f1034c8da4045a1b7aee2d5f78d5d",
      "value": 100
     }
    },
    "c82cd5cfb39e42af888dc187b5d8a58c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "auto"
     }
    },
    "c94eb62fe73b4171937f354e2c2f06fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "black",
      "description_width": ""
     }
    },
    "da6f1034c8da4045a1b7aee2d5f78d5d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": "black",
      "description_width": ""
     }
    },
    "e6c51c60ee844703a0339b2e1dccc64b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c82cd5cfb39e42af888dc187b5d8a58c",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c94eb62fe73b4171937f354e2c2f06fa",
      "value": 59
     }
    },
    "fb91ad428b04480f995aced9d968ba18": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "auto"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
